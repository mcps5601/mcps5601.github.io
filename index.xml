<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ying-Jia Lin</title>
    <link>https://yingjialin.org/</link>
    <description>Recent content on Ying-Jia Lin</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <copyright>Copyright Â© 2008â€“2019, Steve Francia and the lee.so; all rights reserved.</copyright>
    <lastBuildDate>Sun, 07 Aug 2022 11:54:01 +0800</lastBuildDate><atom:link href="https://yingjialin.org/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ying-Jia Lin (æ—è‹±å˜‰)</title>
      <link>https://yingjialin.org/about/</link>
      <pubDate>Sat, 20 Apr 2024 00:00:00 +0000</pubDate>
      
      <guid>https://yingjialin.org/about/</guid>
      <description>Assistant Professor at Department of Artificial Intelligence, College of Intelligent Computing, Chang Gung University Email: yjlin@cgu.edu.tw
Office: B1412, Management Building (14-th floor), No 259, Wenhua 1st Rd, Guishan Dist, Taoyuan City 33302, Taiwan.
ğŸ’¡Prospective students are welcome!! Please contact me via email.
  Hello, I&#39;m Ying-Jia Lin. I am an Assistant Professor at the Department of Artificial Intelligence, College of Intelligent Computing (CoIC), Chang Gung University. Before joining CoIC, I was a postdoctoral researcher at the Department of Computer Science, National Tsing Hua University under the supervision of my PhD advisor, Prof.</description>
    </item>
    
    <item>
      <title>UmlsBERT</title>
      <link>https://yingjialin.org/post/umls-bert/</link>
      <pubDate>Sun, 07 Aug 2022 11:54:01 +0800</pubDate>
      
      <guid>https://yingjialin.org/post/umls-bert/</guid>
      <description>Info  æœƒè­°: NAACL 2021 (è«–æ–‡é€£çµ)(codeé€£çµ) ä½œè€…å–®ä½: University of Waterloo  ç ”ç©¶å‹•æ©Ÿ BioBERT è·Ÿ Clinical BERT åœ¨è¨“ç·´éšæ®µä¸¦æ²’æœ‰åˆ©ç”¨åˆ°å¦‚ UMLS(Unified Medical Language System) é€™ç¨®å°ˆå®¶çŸ¥è­˜
ä¸»è¦æ–¹æ³• ä½¿ç”¨ MIMIC-III NOTEEVENTS ä¾†é è¨“ç·´ BERTï¼Œæ­é…ä»¥ä¸‹å…©ç¨®æ–¹æ³•ä¾†ä½¿ç”¨ UMLS çŸ¥è­˜
UMLS semantic types  BERT çš„è¼¸å…¥é™¤äº†åŸæœ¬ä¸‰ç¨® embeddings (token embeddings, positional embeddings, segment embeddings)ï¼Œæœ¬ç¯‡é‚„åŠ å…¥äº† semantic type embeddings: $$ ST^\top s_w $$ $ST$: semantic embedding matrix ($ST \in\mathbb{R}^{D_s\times d}$)  $D_s$: (åŸºæ–¼MIMIC-IIIçš„) å­—å…¸ä¸­æ‰€å¯ä»¥å°æ‡‰åˆ°çš„ UMLS semantic types ç¸½æ•¸ $d$: Transformer layer çš„ hidden size   $s_w$: ä»»æ„ä¸€å€‹å­— $w$ çš„ one-hot semantic vector ($s_w\in \mathbb{R}^{D_s}$)  å…¶ä¸­æ¯ä¸€å€‹ item ä»£è¡¨ä¸€ç¨® semantic type å¦‚æœ $w$ å®Œå…¨å°æ‡‰ä¸åˆ° UMLS çš„ semantic type å‰‡ $s_w$ å…¨ç‚º 0    MLM  MLM çš„ç›®æ¨™æ”¹ç‚ºå¤šé¡åˆ¥ï¼Œå³æ¨¡å‹ä¹Ÿå¿…é ˆè¦é æ¸¬å‡ºèˆ‡ç›®æ¨™å­—æœ‰ç›¸åŒ CUI çš„å…¶ä»–å¯«æ³•   é‡è¦ç™¼ç¾  UmlsBERT å¯ä»¥æé«˜ MEdNLI è·Ÿå…¶ä»–4å€‹ NER è³‡æ–™é›†çš„è¡¨ç¾ (Table 3) UmlsBERT çš„é è¨“ç·´éç¨‹å¯ä»¥ä½¿æ¨¡å‹æ›´èƒ½å€åˆ†å‡ºä¸åŒçš„ UMLS semantic types (Figure 3)  å‰µæ–°çš„éƒ¨ä»½  é‹ç”¨ UMLS domain knowledge  ç¼ºé»  æ²’æœ‰èˆ‡ BlueBERT æ¯”è¼ƒ å¯¦é©—è‘—é‡åœ¨ NER çš„éƒ¨ä»½ æ‰¾å‡ºç›¸è¿‘é†«å­¸å­—çš„å¯¦é©—ä¸­ (Table 4)ï¼ŒBERT ä¸¦æ²’æœ‰è¡¨ç¾ç‰¹åˆ¥å·®  æˆ‘çš„å•é¡Œ  ä¸çŸ¥é“ semantic embedding matrix $ST$ å¦‚ä½•åˆå§‹åŒ–ï¼Œä»¥åŠ $ST$ æ˜¯å¦ç‚ºå¯è¨“ç·´ä¹‹åƒæ•¸  </description>
    </item>
    
    <item>
      <title>Trees and Distance: Basic Properties</title>
      <link>https://yingjialin.org/post/graph_ch_2_1/</link>
      <pubDate>Mon, 15 Nov 2021 14:49:12 +0800</pubDate>
      
      <guid>https://yingjialin.org/post/graph_ch_2_1/</guid>
      <description>åƒè€ƒæ›¸ç±: Introduction to Graph Theory - Second edition  æ¨¹åŸºæœ¬å®šç¾© acyclic  A graph with no cycle  forest  An acyclic graph  tree  A connected acyclic graph  leaf  A vertex of degree 1 åˆç¨±ä½œ pendant vertex  spanning subgraph  A spanning subgraph of $G$ is a subgraph with vertex set $V(G)$.  spanning tree  A spanning tree is a spanning subgraph that is a tree.</description>
    </item>
    
    <item>
      <title>RadBERT-CL: Factually-Aware Contrastive Learning For Radiology Report Classification</title>
      <link>https://yingjialin.org/post/radbert-cl/</link>
      <pubDate>Mon, 15 Nov 2021 14:38:40 +0800</pubDate>
      
      <guid>https://yingjialin.org/post/radbert-cl/</guid>
      <description>è«–æ–‡è³‡è¨Š  æœƒè­°: Machine Learning for Health (ML4H) 2021 (è«–æ–‡é€£çµ) ä½œè€…å–®ä½: The University of Texas at Austin  ç ”ç©¶å‹•æ©Ÿ  BERT è·Ÿ BlueBert æ²’è¾¦æ³•æŠŠ uncertainty è·Ÿ negation çš„å•é¡Œè™•ç†å¾—å¾ˆå¥½  æœ¬ç¯‡é‡é»  Data augmentation  å› ç‚ºè¦åš contrastive pre-training learning   æ¥µåº¦ä»°è³´ Wu et al. (2020a)  Related work  Fang and Xie (2020) é‡å°æ­£å‘è³‡æ–™ä½¿ç”¨å¥å­å±¤ç´šçš„ back-translation Wu et al. (2020a) æ•´åˆ4ç¨®å¥å­å±¤ç´šçš„è³‡æ–™æ“´å¢  Word deletion Span deletion Reordering Synonym substitution    æ–¹æ³•  åœ¨ pre-training çš„éƒ¨åˆ†é€²è¡Œæ”¹é€²  åˆ©ç”¨ Contrastive pre-training ä¾†å¢åŠ æ¨¡å‹åœ¨ä»»å‹™ä¸Šçš„äº‹å¯¦ç¢ºèªèƒ½åŠ›   è³‡æ–™: radiology reports  MIMIC-CXR (Johnson et al.</description>
    </item>
    
    <item>
      <title>Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</title>
      <link>https://yingjialin.org/post/sbert/</link>
      <pubDate>Thu, 07 Oct 2021 22:25:52 +0800</pubDate>
      
      <guid>https://yingjialin.org/post/sbert/</guid>
      <description>è«–æ–‡è³‡è¨Š  æœƒè­°: EMNLP 2019 (è«–æ–‡é€£çµ)(codeé€£çµ) ä½œè€…å–®ä½: UKPLab ä¸»è¦ä»»å‹™: semantic textual similarity (STS)  å¿«é€Ÿé‡é»  é€™æ˜¯ä¸€å€‹ sentence embeddings çš„å·¥ä½œ æå‡º SBERT å’Œ SRoBERTa  åŸºæ–¼ siamese å’Œ triplet loss æ¶æ§‹   åœ¨ NLI è³‡æ–™é›†ä¸Šé€²è¡Œ fine-tuningï¼Œè¡¨ç¾æ¯” InferSentã€Universal Sentence Encoder é‚„è¦å¥½ åœ¨ STS è³‡æ–™é›†ä¸Šè´é InferSent 11.7 åˆ†ã€è´é Universal Sentence Encoder 5.5 åˆ† åœ¨ SentEval çš„å…©å€‹ä»»å‹™ä¸Šå¾—åˆ° 2.1 å’Œ 2.6 åˆ†çš„æå‡  èƒŒæ™¯ BERT  å°‡å…©å€‹å¥å­ä»¥SEPåˆèµ·ä¾†ç•¶æˆ1å€‹å¥å­ åœ¨ inference æ™‚æœƒå¾ˆæ²’æœ‰æ•ˆç‡  inference æ™‚æ˜¯è¦æ‰¾åˆ°æœ€ä½³çš„é…å°çµ„åˆ å‡è¨­æœ‰10,000å€‹å¥å­ï¼ŒBERT å°±è¦åš n*(n-1)/2 æ¬¡ï¼Œå…± 49,995,000 æ¬¡  10,000å€‹å¥å­åªæœƒæ‰¾æœ¬èº«ä»¥å¤–çš„10,000-1å€‹å¥å­ å› ç‚ºæ˜¯æ‰¾æˆå°å¥å­ï¼Œæ‰€ä»¥ç¸½æ¬¡æ•¸é™¤ä»¥2   ä»¥ V100 ä¾†åšé‹ç®—çš„è©±éœ€è¦èŠ±è²» 65 å°æ™‚    æ–¹æ³• æ¨¡å‹  å° BERT/ RoBERTa çš„è¼¸å‡ºä½¿ç”¨æ± åŒ– (pooling) çš„æ–¹æ³•é€²è¡Œè™•ç†: (1) å– CLS token (2) å– MEAN (3) å– MAX ä¾†å¾—åˆ°å›ºå®šå¤§å° (fixed sized) çš„å¥å‘é‡ æœ¬è«–æ–‡é è¨­ä½¿ç”¨ ==MEAN== ä½œç‚º pooling æ–¹æ³•  åˆ†é¡ä»»å‹™çš„æœ€ä½³åŒ–æ–¹å¼   $o=\text{softmax}(W_t(u,v,|u-v|))$</description>
    </item>
    
    <item>
      <title>Math Terms</title>
      <link>https://yingjialin.org/post/math-terms/</link>
      <pubDate>Tue, 02 Mar 2021 14:11:38 +0800</pubDate>
      
      <guid>https://yingjialin.org/post/math-terms/</guid>
      <description>æ•¸å­¸è­‰æ˜å¸¸ç”¨åè©  Definition (å®šç¾©): è§£é‡‹æŸå€‹æ•¸å­¸ç”¨èªçš„æ„ç¾© Theorem (å®šç†): é‡è¦çš„æ•¸å­¸æ•˜è¿°æˆ–ç†è«–ï¼Œé€šå¸¸ç¶“ç”±è­‰æ˜è€Œå¾— Axiom (å…¬ç†): æ™®éå¯ä»¥è¢«æ¥å—ä¸”ä¸ç”¨ç¶“éè­‰æ˜çš„ç¾è±¡æˆ–æ•˜è¿° Proposition (å‘½é¡Œ): å’Œå®šç†æ„æ¶µç›¸ä¼¼ï¼Œå¯èƒ½æ˜¯é‡è¦ç¨‹åº¦è¼ƒä½çš„å°çµæœ Lemma (å¼•ç†): è¼”åŠ©è­‰æ˜ä»¥å¼•å°å‡ºå®šç†çš„å°çµæœï¼Œå› ç‚ºè­‰æ˜å®šç†çš„éç¨‹å¯èƒ½ç¯‡å¹…å¾ˆé•· Remark (è©•è«–): å°æ–¼å®šç†æˆ–è­‰æ˜çµæœæ‰€å¼•ç”³å‡ºä¾†çš„æ•˜è¿° Corollary (æ¨è«–): åŸºæ–¼å®šç†ä¾†é€²ä¸€æ­¥æ¨å°çš„è«–è¿°ï¼Œé€šå¸¸ä¹Ÿæœ‰è­‰æ˜è¼”åŠ©  </description>
    </item>
    
    <item>
      <title>Math Terms</title>
      <link>https://yingjialin.org/posts/math-terms/</link>
      <pubDate>Tue, 02 Mar 2021 14:11:38 +0800</pubDate>
      
      <guid>https://yingjialin.org/posts/math-terms/</guid>
      <description>æ•¸å­¸è­‰æ˜å¸¸ç”¨åè©  Definition (å®šç¾©): è§£é‡‹æŸå€‹æ•¸å­¸ç”¨èªçš„æ„ç¾© Theorem (å®šç†): é‡è¦çš„æ•¸å­¸æ•˜è¿°æˆ–ç†è«–ï¼Œé€šå¸¸ç¶“ç”±è­‰æ˜è€Œå¾— Axiom (å…¬ç†): æ™®éå¯ä»¥è¢«æ¥å—ä¸”ä¸ç”¨ç¶“éè­‰æ˜çš„ç¾è±¡æˆ–æ•˜è¿° Proposition (å‘½é¡Œ): å’Œå®šç†æ„æ¶µç›¸ä¼¼ï¼Œå¯èƒ½æ˜¯é‡è¦ç¨‹åº¦è¼ƒä½çš„å°çµæœ Lemma (å¼•ç†): è¼”åŠ©è­‰æ˜ä»¥å¼•å°å‡ºå®šç†çš„å°çµæœï¼Œå› ç‚ºè­‰æ˜å®šç†çš„éç¨‹å¯èƒ½ç¯‡å¹…å¾ˆé•· Remark (è©•è«–): å°æ–¼å®šç†æˆ–è­‰æ˜çµæœæ‰€å¼•ç”³å‡ºä¾†çš„æ•˜è¿° Corollary (æ¨è«–): åŸºæ–¼å®šç†ä¾†é€²ä¸€æ­¥æ¨å°çš„è«–è¿°ï¼Œé€šå¸¸ä¹Ÿæœ‰è­‰æ˜è¼”åŠ©  </description>
    </item>
    
    <item>
      <title>Deep Learning - 2025 Fall</title>
      <link>https://yingjialin.org/course/dl/2025-fall/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yingjialin.org/course/dl/2025-fall/</guid>
      <description>æ­¡è¿ä¾†åˆ° 2025 å¹´ç§‹å­£å­¸æœŸçš„ Deep Learning èª²ç¨‹é é¢ ğŸ“ã€‚
é é¢æ–½å·¥ä¸­ ğŸš§
èª²ç¨‹è³‡è¨Š  æˆèª²æ•™å¸«: Ying-Jia Lin æ™‚é–“: æ¯é€±ä¸‰ 13:10â€“16:00 åœ°é»: ç®¡ç†å¤§æ¨“ 3æ¨“ é›»è…¦æ•™å®¤ B0301C  </description>
    </item>
    
    <item>
      <title>ç”Ÿæˆå¼AIï¼šæ–‡å­—èˆ‡åœ–åƒç”Ÿæˆçš„åŸç†èˆ‡å¯¦å‹™ (2025 Fall)</title>
      <link>https://yingjialin.org/course/genai/2025-fall/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://yingjialin.org/course/genai/2025-fall/</guid>
      <description>æ­¡è¿ä¾†åˆ°ç”Ÿæˆå¼AIï¼šæ–‡å­—èˆ‡åœ–åƒç”Ÿæˆçš„åŸç†èˆ‡å¯¦å‹™çš„èª²ç¨‹é é¢ğŸ“
æœ¬èª²ç¨‹ç‚ºTAICAæ‰€é–‹è¨­ä¹‹èª²ç¨‹ï¼Œé•·åºšå¤§å­¸æ ¡å…§å±¬æ–¼è¡›æ˜Ÿèª²ç¨‹ï¼Œé•·åºšå¤§å­¸å­¸ç”Ÿå¯ä»¥ é¸ä¿®ã€‚
èª²ç¨‹åŸºæœ¬è³‡æ–™  é–‹æˆæ•™å¸«ï¼šè”¡ç‚é¾ å‰¯æ•™æˆ (åœ‹ç«‹æ”¿æ²»å¤§å­¸æ‡‰ç”¨æ•¸å­¸ç³») æ ¡å…§å”åŒæ•™å¸«ï¼šæ—è‹±å˜‰ åŠ©ç†æ•™æˆ (é•·åºšå¤§å­¸äººå·¥æ™ºæ…§å­¸ç³») é–‹èª²ç´šåˆ¥ï¼šå¤§å­¸éƒ¨ï¼ç ”ç©¶æ‰€ æˆèª²èªè¨€ï¼šä¸­æ–‡ å­¸åˆ†æ•¸ï¼š3 ä¸Šèª²æ™‚é–“ï¼šæ¯é€±äºŒ 16:00â€“19:00 ä¸Šèª²åœ°é»ï¼šé•·åºšå¤§å­¸ç®¡ç†å¤§æ¨“ 10 æ¨“ B1008 é è·ä¸Šèª²ä½ç½®ï¼š  Facebookã€æ”¿å¤§æ‡‰æ•¸ç³»ç›´æ’­ä¸­å¿ƒã€‘ï¼šhttps://facebook.com/groups/nccumathonline/ èª²ç¨‹ YouTubeï¼ˆå« 1132 èª²ç¨‹éŒ„å½±ï¼‰ï¼šhttps://www.youtube.com/@ive-iveai   å”åŒæ•™å¸« Office Hourï¼šæ¯é€±ä¸‰ 13:00â€“14:00ï¼Œç®¡ç†å¤§æ¨“14æ¨“ 1412 å®¤   èª²ç¨‹æ¦‚è¿° æœ¬èª²ç¨‹å…¼å…·ç†è«–æ·±åº¦èˆ‡å¯¦ä½œæ¨‚è¶£ï¼Œå°ˆç‚ºå¸Œæœ›æ·±å…¥äº†è§£ç”Ÿæˆå¼ AI æŠ€è¡“èˆ‡æ‡‰ç”¨çš„å­¸ç”Ÿè¨­è¨ˆã€‚ä¸è«–åŸºç¤æˆ–é€²éšï¼Œèª²ç¨‹å°‡å¸¶é ˜åŒå­¸æ¢ç´¢ç”Ÿæˆå¼ AI çš„ç„¡é™å¯èƒ½ã€‚å…§å®¹æ¶µè“‹ç¥ç¶“ç¶²è·¯ã€GANã€Transformerã€å¤§å‹èªè¨€æ¨¡å‹ã€RAGã€AI Agentsã€Diffusion Models ç­‰ï¼Œä¸¦å¯¦ä½œæ–‡å­—ç”Ÿæˆã€åœ–åƒç”Ÿæˆç­‰å¤šæ¨£æ‡‰ç”¨ï¼Œä½¿ç”¨çš„å·¥å…·åŒ…æ‹¬ OpenAI APIã€LangChainã€HuggingFaceã€AISuite ç­‰ã€‚
 èª²ç¨‹ç›®æ¨™  ç†è§£ç”Ÿæˆå¼ AI çš„æ ¸å¿ƒæŠ€è¡“ï¼ˆç¥ç¶“ç¶²è·¯ã€GANã€Transformerã€å¤§å‹èªè¨€æ¨¡å‹ã€RAGã€AI Agentsã€Diffusion Modelsï¼‰ã€‚ å¯¦éš›é‹ç”¨ OpenAI APIã€LangChainã€AISuiteã€HuggingFaceã€Fooocus ç­‰å·¥å…·é–‹ç™¼æ‡‰ç”¨ã€‚ æ¢è¨ç”Ÿæˆå¼ AI çš„ç¤¾æœƒèˆ‡å€«ç†æŒ‘æˆ°ï¼Œæå‡ºå‰µæ–°è§£æ±ºæ–¹æ¡ˆã€‚ å®ŒæˆæœŸæœ«å°ˆé¡Œï¼Œæ•´åˆæ‰€å­¸å…§å®¹ä¸¦å±•ç¤ºä¸€å€‹å¯¦ç”¨çš„ç”Ÿæˆå¼ AI ç³»çµ±ã€‚   èª²ç¨‹ç‰¹è‰²  å¾ªåºæ¼¸é€²ï¼šå¾ç¥ç¶“ç¶²è·¯åŸºç¤åˆ°é€²éšæ¨¡å‹èˆ‡æ‡‰ç”¨ã€‚ å¯¦ä½œç‚ºä¸»ã€ç†è«–ç‚ºè¼”ï¼šèª²å ‚ä½¿ç”¨ Colab é€²è¡Œç¨‹å¼å¯¦ä½œï¼Œæ­é…å…·æŒ‘æˆ°æ€§çš„èª²å¾Œä½œæ¥­ã€‚ æ¶µè“‹æœ€æ–°æŠ€è¡“ï¼šæŒæ¡ç”Ÿæˆå¼ AI ç™¼å±•è¶¨å‹¢ã€‚ å¤šå…ƒæ‡‰ç”¨å ´æ™¯ï¼šæ–‡å­—ç”Ÿæˆã€åœ–åƒç”Ÿæˆã€å°è©±æ©Ÿå™¨äººã€Agentic AI ç­‰ã€‚ å¼·èª¿å€«ç†èˆ‡æ‡‰ç”¨ï¼šåæ€ AI çš„ç¤¾æœƒå½±éŸ¿ï¼Œå¼·èª¿è² è²¬ä»»ä½¿ç”¨ã€‚   èª²ç¨‹å…§å®¹å¤§ç¶±    é€±æ¬¡ æ—¥æœŸ ä¸»é¡Œ éŒ„å½± ä½œæ¥­å…§å®¹ (æˆªæ­¢æ—¥)      1 9/2 èª²ç¨‹ä»‹ç´¹èˆ‡ç”Ÿæˆå¼ AI æ¦‚è¿°    HW1 (9/15)    2 9/9 ç¥ç¶“ç¶²è·¯çš„æ¦‚å¿µ    HW2 (9/23)    3 9/16 ç´…æ¥µä¸€æ™‚çš„ç”Ÿæˆå°æŠ—ç¶²è·¯ (GAN)    HW3 (9/29)    4 9/23 å¤§å‹èªè¨€æ¨¡å‹åŸºç¤èˆ‡ seq2seq æ¨¡å‹    HW4 (10/06)    5 9/30 Transformers å…¨æ”»ç•¥    HW5 (10/13)    6 10/7 å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ‡‰ç”¨èˆ‡å€«ç†è­°é¡Œçš„æŒ‘æˆ°    HW6 (10/20)    7 10/14 æ‰“é€ è‡ªå·±çš„å°è©±æ©Ÿå™¨äººï¼ˆAISuiteï¼‰    HW7 (10/27)    8 10/21 ç‰¹åˆ¥è¬›åº§ - Vibe Coding    æœ¬é€±æ²’æœ‰ä½œæ¥­    9 10/28 æª¢ç´¢å¢å¼·ç”Ÿæˆï¼ˆRAGï¼‰çš„åŸç†åŠå¯¦ä½œ      10 11/4 Agentic AI èˆ‡ AI Agents      11 11/11 è®Šåˆ†è‡ªç·¨ç¢¼å™¨ï¼ˆVAEï¼‰èˆ‡ Diffusion Models      12 11/18 æ–‡å­—ç”Ÿåœ– AI åŸç†èˆ‡å¯¦ä½œï¼ˆDiffusion Models é€²éšä¸»é¡Œï¼‰      13 11/25 ç”¨ Fooocus å¯¦ç¾ Diffusion Models çš„é€²éšæŠ€è¡“      14 12/2 ç”Ÿæˆå¼ AI æµè¡Œå·¥å…·åŠæ‡‰ç”¨ç¯„ä¾‹      15 12/9 ç”Ÿæˆå¼ AI æ‡‰ç”¨èˆ‡ç™¼å±•è¶¨å‹¢      16 12/16 ç·šä¸ŠæœŸæœ«å°ˆé¡Œæˆæœåˆ†äº«ï¼ˆGather.</description>
    </item>
    
  </channel>
</rss>
