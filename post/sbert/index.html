<!DOCTYPE html>


































<html
  class="not-ready text-sm lg:text-base"
  style="--bg: #faf6f1"
  lang="en"
>
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta
    name="viewport"
    content="width=device-width, initial-scale=1, shrink-to-fit=no"
  />

  
  <title>Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks - Ying-Jia Lin</title>

  
  <meta name="theme-color" />

  
  
  
  <meta name="description" content="è«–æ–‡è³‡è¨Š  æœƒè­°: EMNLP 2019 (è«–æ–‡é€£çµ)(codeé€£çµ) ä½œè€…å–®ä½: UKPLab ä¸»è¦ä»»å‹™: semantic textual similarity (STS)  å¿«é€Ÿé‡é»  é€™æ˜¯ä¸€å€‹ sentence embeddings çš„å·¥ä½œ æå‡º SBERT å’Œ SRoBERTa  åŸºæ–¼ siamese å’Œ triplet loss æ¶æ§‹   åœ¨ NLI è³‡æ–™é›†ä¸Šé€²è¡Œ fine-tuningï¼Œè¡¨ç¾æ¯” InferSentã€Universal Sentence Encoder é‚„è¦å¥½ åœ¨ STS è³‡æ–™é›†ä¸Šè´é InferSent 11.7 åˆ†ã€è´é Universal Sentence Encoder 5.5 åˆ† åœ¨ SentEval çš„å…©å€‹ä»»å‹™ä¸Šå¾—åˆ° 2.1 å’Œ 2.6 åˆ†çš„æå‡  èƒŒæ™¯ BERT  å°‡å…©å€‹å¥å­ä»¥SEPåˆèµ·ä¾†ç•¶æˆ1å€‹å¥å­ åœ¨ inference æ™‚æœƒå¾ˆæ²’æœ‰æ•ˆç‡  inference æ™‚æ˜¯è¦æ‰¾åˆ°æœ€ä½³çš„é…å°çµ„åˆ å‡è¨­æœ‰10,000å€‹å¥å­ï¼ŒBERT å°±è¦åš n*(n-1)/2 æ¬¡ï¼Œå…± 49,995,000 æ¬¡  10,000å€‹å¥å­åªæœƒæ‰¾æœ¬èº«ä»¥å¤–çš„10,000-1å€‹å¥å­ å› ç‚ºæ˜¯æ‰¾æˆå°å¥å­ï¼Œæ‰€ä»¥ç¸½æ¬¡æ•¸é™¤ä»¥2   ä»¥ V100 ä¾†åšé‹ç®—çš„è©±éœ€è¦èŠ±è²» 65 å°æ™‚    æ–¹æ³• æ¨¡å‹  å° BERT/ RoBERTa çš„è¼¸å‡ºä½¿ç”¨æ± åŒ– (pooling) çš„æ–¹æ³•é€²è¡Œè™•ç†: (1) å– CLS token (2) å– MEAN (3) å– MAX ä¾†å¾—åˆ°å›ºå®šå¤§å° (fixed sized) çš„å¥å‘é‡ æœ¬è«–æ–‡é è¨­ä½¿ç”¨ ==MEAN== ä½œç‚º pooling æ–¹æ³•  åˆ†é¡ä»»å‹™çš„æœ€ä½³åŒ–æ–¹å¼   $o=\text{softmax}(W_t(u,v,|u-v|))$" />
  <meta name="author" content="Greetings!ğŸ‘¨â€ğŸ’»" />
  

  
  
  
  
  
  
  <link rel="preload stylesheet" as="style" href="https://mcps5601.github.io/main.min.css" />

  
  <script
    defer
    src="https://mcps5601.github.io/highlight.min.js"
    onload="hljs.initHighlightingOnLoad();"
  ></script>
  

  
   
  <link rel="preload" as="image" href="https://mcps5601.github.io/theme.png" />

  
  
  
  

  
  <link rel="preload" as="image" href="https://mcps5601.github.io/scholar.svg" />
  
  <link rel="preload" as="image" href="https://mcps5601.github.io/twitter.svg" />
  
  <link rel="preload" as="image" href="https://mcps5601.github.io/github.svg" />
  

  
  <link rel="icon" href="https://mcps5601.github.io/favicon.ico" />
  <link rel="apple-touch-icon" href="https://mcps5601.github.io/apple-touch-icon.png" />

  
  <meta name="generator" content="Hugo 0.88.1" />

  
  

  
  
  
  
  
  
  
  <meta property="og:title" content="Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks" />
<meta property="og:description" content="è«–æ–‡è³‡è¨Š  æœƒè­°: EMNLP 2019 (è«–æ–‡é€£çµ)(codeé€£çµ) ä½œè€…å–®ä½: UKPLab ä¸»è¦ä»»å‹™: semantic textual similarity (STS)  å¿«é€Ÿé‡é»  é€™æ˜¯ä¸€å€‹ sentence embeddings çš„å·¥ä½œ æå‡º SBERT å’Œ SRoBERTa  åŸºæ–¼ siamese å’Œ triplet loss æ¶æ§‹   åœ¨ NLI è³‡æ–™é›†ä¸Šé€²è¡Œ fine-tuningï¼Œè¡¨ç¾æ¯” InferSentã€Universal Sentence Encoder é‚„è¦å¥½ åœ¨ STS è³‡æ–™é›†ä¸Šè´é InferSent 11.7 åˆ†ã€è´é Universal Sentence Encoder 5.5 åˆ† åœ¨ SentEval çš„å…©å€‹ä»»å‹™ä¸Šå¾—åˆ° 2.1 å’Œ 2.6 åˆ†çš„æå‡  èƒŒæ™¯ BERT  å°‡å…©å€‹å¥å­ä»¥SEPåˆèµ·ä¾†ç•¶æˆ1å€‹å¥å­ åœ¨ inference æ™‚æœƒå¾ˆæ²’æœ‰æ•ˆç‡  inference æ™‚æ˜¯è¦æ‰¾åˆ°æœ€ä½³çš„é…å°çµ„åˆ å‡è¨­æœ‰10,000å€‹å¥å­ï¼ŒBERT å°±è¦åš n*(n-1)/2 æ¬¡ï¼Œå…± 49,995,000 æ¬¡  10,000å€‹å¥å­åªæœƒæ‰¾æœ¬èº«ä»¥å¤–çš„10,000-1å€‹å¥å­ å› ç‚ºæ˜¯æ‰¾æˆå°å¥å­ï¼Œæ‰€ä»¥ç¸½æ¬¡æ•¸é™¤ä»¥2   ä»¥ V100 ä¾†åšé‹ç®—çš„è©±éœ€è¦èŠ±è²» 65 å°æ™‚    æ–¹æ³• æ¨¡å‹  å° BERT/ RoBERTa çš„è¼¸å‡ºä½¿ç”¨æ± åŒ– (pooling) çš„æ–¹æ³•é€²è¡Œè™•ç†: (1) å– CLS token (2) å– MEAN (3) å– MAX ä¾†å¾—åˆ°å›ºå®šå¤§å° (fixed sized) çš„å¥å‘é‡ æœ¬è«–æ–‡é è¨­ä½¿ç”¨ ==MEAN== ä½œç‚º pooling æ–¹æ³•  åˆ†é¡ä»»å‹™çš„æœ€ä½³åŒ–æ–¹å¼   $o=\text{softmax}(W_t(u,v,|u-v|))$" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://mcps5601.github.io/post/sbert/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2021-10-07T22:25:52+08:00" />
<meta property="article:modified_time" content="2021-10-07T22:25:52+08:00" />


  
  <meta itemprop="name" content="Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks">
<meta itemprop="description" content="è«–æ–‡è³‡è¨Š  æœƒè­°: EMNLP 2019 (è«–æ–‡é€£çµ)(codeé€£çµ) ä½œè€…å–®ä½: UKPLab ä¸»è¦ä»»å‹™: semantic textual similarity (STS)  å¿«é€Ÿé‡é»  é€™æ˜¯ä¸€å€‹ sentence embeddings çš„å·¥ä½œ æå‡º SBERT å’Œ SRoBERTa  åŸºæ–¼ siamese å’Œ triplet loss æ¶æ§‹   åœ¨ NLI è³‡æ–™é›†ä¸Šé€²è¡Œ fine-tuningï¼Œè¡¨ç¾æ¯” InferSentã€Universal Sentence Encoder é‚„è¦å¥½ åœ¨ STS è³‡æ–™é›†ä¸Šè´é InferSent 11.7 åˆ†ã€è´é Universal Sentence Encoder 5.5 åˆ† åœ¨ SentEval çš„å…©å€‹ä»»å‹™ä¸Šå¾—åˆ° 2.1 å’Œ 2.6 åˆ†çš„æå‡  èƒŒæ™¯ BERT  å°‡å…©å€‹å¥å­ä»¥SEPåˆèµ·ä¾†ç•¶æˆ1å€‹å¥å­ åœ¨ inference æ™‚æœƒå¾ˆæ²’æœ‰æ•ˆç‡  inference æ™‚æ˜¯è¦æ‰¾åˆ°æœ€ä½³çš„é…å°çµ„åˆ å‡è¨­æœ‰10,000å€‹å¥å­ï¼ŒBERT å°±è¦åš n*(n-1)/2 æ¬¡ï¼Œå…± 49,995,000 æ¬¡  10,000å€‹å¥å­åªæœƒæ‰¾æœ¬èº«ä»¥å¤–çš„10,000-1å€‹å¥å­ å› ç‚ºæ˜¯æ‰¾æˆå°å¥å­ï¼Œæ‰€ä»¥ç¸½æ¬¡æ•¸é™¤ä»¥2   ä»¥ V100 ä¾†åšé‹ç®—çš„è©±éœ€è¦èŠ±è²» 65 å°æ™‚    æ–¹æ³• æ¨¡å‹  å° BERT/ RoBERTa çš„è¼¸å‡ºä½¿ç”¨æ± åŒ– (pooling) çš„æ–¹æ³•é€²è¡Œè™•ç†: (1) å– CLS token (2) å– MEAN (3) å– MAX ä¾†å¾—åˆ°å›ºå®šå¤§å° (fixed sized) çš„å¥å‘é‡ æœ¬è«–æ–‡é è¨­ä½¿ç”¨ ==MEAN== ä½œç‚º pooling æ–¹æ³•  åˆ†é¡ä»»å‹™çš„æœ€ä½³åŒ–æ–¹å¼   $o=\text{softmax}(W_t(u,v,|u-v|))$"><meta itemprop="datePublished" content="2021-10-07T22:25:52+08:00" />
<meta itemprop="dateModified" content="2021-10-07T22:25:52+08:00" />
<meta itemprop="wordCount" content="237">
<meta itemprop="keywords" content="è«–æ–‡,NLP,BERT,sentence_embeddings," />
  
  <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"/>
<meta name="twitter:description" content="è«–æ–‡è³‡è¨Š  æœƒè­°: EMNLP 2019 (è«–æ–‡é€£çµ)(codeé€£çµ) ä½œè€…å–®ä½: UKPLab ä¸»è¦ä»»å‹™: semantic textual similarity (STS)  å¿«é€Ÿé‡é»  é€™æ˜¯ä¸€å€‹ sentence embeddings çš„å·¥ä½œ æå‡º SBERT å’Œ SRoBERTa  åŸºæ–¼ siamese å’Œ triplet loss æ¶æ§‹   åœ¨ NLI è³‡æ–™é›†ä¸Šé€²è¡Œ fine-tuningï¼Œè¡¨ç¾æ¯” InferSentã€Universal Sentence Encoder é‚„è¦å¥½ åœ¨ STS è³‡æ–™é›†ä¸Šè´é InferSent 11.7 åˆ†ã€è´é Universal Sentence Encoder 5.5 åˆ† åœ¨ SentEval çš„å…©å€‹ä»»å‹™ä¸Šå¾—åˆ° 2.1 å’Œ 2.6 åˆ†çš„æå‡  èƒŒæ™¯ BERT  å°‡å…©å€‹å¥å­ä»¥SEPåˆèµ·ä¾†ç•¶æˆ1å€‹å¥å­ åœ¨ inference æ™‚æœƒå¾ˆæ²’æœ‰æ•ˆç‡  inference æ™‚æ˜¯è¦æ‰¾åˆ°æœ€ä½³çš„é…å°çµ„åˆ å‡è¨­æœ‰10,000å€‹å¥å­ï¼ŒBERT å°±è¦åš n*(n-1)/2 æ¬¡ï¼Œå…± 49,995,000 æ¬¡  10,000å€‹å¥å­åªæœƒæ‰¾æœ¬èº«ä»¥å¤–çš„10,000-1å€‹å¥å­ å› ç‚ºæ˜¯æ‰¾æˆå°å¥å­ï¼Œæ‰€ä»¥ç¸½æ¬¡æ•¸é™¤ä»¥2   ä»¥ V100 ä¾†åšé‹ç®—çš„è©±éœ€è¦èŠ±è²» 65 å°æ™‚    æ–¹æ³• æ¨¡å‹  å° BERT/ RoBERTa çš„è¼¸å‡ºä½¿ç”¨æ± åŒ– (pooling) çš„æ–¹æ³•é€²è¡Œè™•ç†: (1) å– CLS token (2) å– MEAN (3) å– MAX ä¾†å¾—åˆ°å›ºå®šå¤§å° (fixed sized) çš„å¥å‘é‡ æœ¬è«–æ–‡é è¨­ä½¿ç”¨ ==MEAN== ä½œç‚º pooling æ–¹æ³•  åˆ†é¡ä»»å‹™çš„æœ€ä½³åŒ–æ–¹å¼   $o=\text{softmax}(W_t(u,v,|u-v|))$"/>

  
  
</head>

  <body class="text-black duration-200 ease-out dark:text-white">
    <header class="mx-auto flex h-[5rem] max-w-3xl px-8 lg:justify-center">
  <div class="relative z-50 mr-auto flex items-center">
    <a
      class="-translate-x-[1px] -translate-y-0.5 text-3xl font-bold"
      href="https://mcps5601.github.io/"
      >Ying-Jia Lin</a
    >
    <div
      class="btn-dark text-[0] ml-6 h-6 w-6 shrink-0 cursor-pointer [background:url(./theme.png)_left_center/_auto_theme('spacing.6')_no-repeat] [transition:_background-position_0.4s_steps(5)] dark:[background-position:right]"
      role="button"
      aria-label="Dark"
    ></div>
  </div>

  <div
    class="btn-menu relative z-50 -mr-8 flex h-[5rem] w-[5rem] shrink-0 cursor-pointer flex-col items-center justify-center gap-2.5 lg:hidden"
    role="button"
    aria-label="Menu"
  ></div>

  
  <script>
    
    const htmlClass = document.documentElement.classList;
    setTimeout(() => {
      htmlClass.remove('not-ready');
    }, 10);

    
    const btnMenu = document.querySelector('.btn-menu');
    btnMenu.addEventListener('click', () => {
      htmlClass.toggle('open');
    });

    
    const metaTheme = document.querySelector('meta[name="theme-color"]');
    const lightBg = `"#faf6f1"`.replace(/"/g, '');
    const setDark = (isDark) => {
      metaTheme.setAttribute('content', isDark ? '#000' : lightBg);
      htmlClass[isDark ? 'add' : 'remove']('dark');
      localStorage.setItem('dark', isDark);
    };

    
    const darkScheme = window.matchMedia('(prefers-color-scheme: dark)');
    if (htmlClass.contains('dark')) {
      setDark(true);
    } else {
      const darkVal = localStorage.getItem('dark');
      setDark(darkVal ? darkVal === 'true' : darkScheme.matches);
    }

    
    darkScheme.addEventListener('change', (event) => {
      setDark(event.matches);
    });

    
    const btnDark = document.querySelector('.btn-dark');
    btnDark.addEventListener('click', () => {
      setDark(localStorage.getItem('dark') !== 'true');
    });
  </script>

  <div
    class="nav-wrapper fixed inset-x-0 top-full z-40 flex h-full select-none flex-col justify-center pb-16 duration-200 dark:bg-black lg:static lg:h-auto lg:flex-row lg:!bg-transparent lg:pb-0 lg:transition-none"
  >
    
    
    <nav class="lg:ml-12 lg:flex lg:flex-row lg:items-center lg:space-x-6">
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="/about/"
        >About</a
      >
      
      <a
        class="block text-center text-2xl leading-[5rem] lg:text-base lg:font-normal"
        href="https://ila-lab.github.io/"
        >Lab</a
      >
      
    </nav>
    

    
    <nav
      class="mt-12 flex justify-center space-x-10 dark:invert lg:mt-0 lg:ml-12 lg:items-center lg:space-x-6"
    >
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./scholar.svg)"
        href="https://scholar.google.com.tw/citations?user=TM4JxJkAAAAJ&hl=zh-TW&oi=ao"
        target="_blank"
        rel="me"
      >
        scholar
      </a>
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./twitter.svg)"
        href="https://twitter.com/mcps5601"
        target="_blank"
        rel="me"
      >
        twitter
      </a>
      
      <a
        class="h-8 w-8 text-[0] [background:var(--url)_center_center/cover_no-repeat] lg:h-6 lg:w-6"
        style="--url: url(./github.svg)"
        href="https://github.com/mcps5601"
        target="_blank"
        rel="me"
      >
        github
      </a>
      
    </nav>
    
  </div>
</header>


    <main
      class="prose prose-neutral relative mx-auto min-h-[calc(100%-10rem)] max-w-3xl px-8 pt-16 pb-24 dark:prose-invert"
    >
      

<article>
  <header class="mb-20">
    <h1 class="!my-0 pb-2.5">Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks</h1>

    
    <div class="text-sm opacity-60">
      
      <time>Oct 7, 2021</time>
      
      
      
      
    </div>
    
  </header>

  <section><h2 id="è«–æ–‡è³‡è¨Š">è«–æ–‡è³‡è¨Š</h2>
<ul>
<li>æœƒè­°: EMNLP 2019 (<a href="https://aclanthology.org/D19-1410.pdf">è«–æ–‡é€£çµ</a>)(<a href="https://github.com/UKPLab/sentence-transformers">codeé€£çµ</a>)</li>
<li>ä½œè€…å–®ä½: UKPLab</li>
<li>ä¸»è¦ä»»å‹™: semantic  textual  similarity  (STS)</li>
</ul>
<h2 id="å¿«é€Ÿé‡é»">å¿«é€Ÿé‡é»</h2>
<ul>
<li>é€™æ˜¯ä¸€å€‹ sentence embeddings çš„å·¥ä½œ</li>
<li>æå‡º SBERT å’Œ SRoBERTa
<ul>
<li>åŸºæ–¼ siamese å’Œ triplet loss æ¶æ§‹</li>
</ul>
</li>
<li>åœ¨ NLI è³‡æ–™é›†ä¸Šé€²è¡Œ fine-tuningï¼Œè¡¨ç¾æ¯” InferSentã€Universal Sentence Encoder é‚„è¦å¥½</li>
<li>åœ¨ STS è³‡æ–™é›†ä¸Šè´é InferSent 11.7 åˆ†ã€è´é Universal Sentence Encoder 5.5 åˆ†</li>
<li>åœ¨ SentEval çš„å…©å€‹ä»»å‹™ä¸Šå¾—åˆ° 2.1 å’Œ 2.6 åˆ†çš„æå‡</li>
</ul>
<h2 id="èƒŒæ™¯">èƒŒæ™¯</h2>
<h3 id="bert">BERT</h3>
<ul>
<li>å°‡å…©å€‹å¥å­ä»¥<code>SEP</code>åˆèµ·ä¾†ç•¶æˆ1å€‹å¥å­</li>
<li>åœ¨ inference æ™‚æœƒå¾ˆæ²’æœ‰æ•ˆç‡
<ul>
<li>inference æ™‚æ˜¯è¦æ‰¾åˆ°æœ€ä½³çš„é…å°çµ„åˆ</li>
<li>å‡è¨­æœ‰10,000å€‹å¥å­ï¼ŒBERT å°±è¦åš n*(n-1)/2 æ¬¡ï¼Œå…± 49,995,000 æ¬¡
<ul>
<li>10,000å€‹å¥å­åªæœƒæ‰¾æœ¬èº«ä»¥å¤–çš„10,000-1å€‹å¥å­</li>
<li>å› ç‚ºæ˜¯æ‰¾æˆå°å¥å­ï¼Œæ‰€ä»¥ç¸½æ¬¡æ•¸é™¤ä»¥2</li>
</ul>
</li>
<li>ä»¥ V100 ä¾†åšé‹ç®—çš„è©±éœ€è¦èŠ±è²» 65 å°æ™‚</li>
</ul>
</li>
</ul>
<h2 id="æ–¹æ³•">æ–¹æ³•</h2>
<h3 id="æ¨¡å‹">æ¨¡å‹</h3>
<ul>
<li>å° BERT/ RoBERTa çš„è¼¸å‡ºä½¿ç”¨æ± åŒ– (pooling) çš„æ–¹æ³•é€²è¡Œè™•ç†:
(1) å– <code>CLS</code> token
(2) å– MEAN
(3) å– MAX
ä¾†å¾—åˆ°å›ºå®šå¤§å° (fixed sized) çš„å¥å‘é‡</li>
<li>æœ¬è«–æ–‡é è¨­ä½¿ç”¨ ==MEAN== ä½œç‚º pooling æ–¹æ³•</li>
</ul>
<h3 id="åˆ†é¡ä»»å‹™çš„æœ€ä½³åŒ–æ–¹å¼">åˆ†é¡ä»»å‹™çš„æœ€ä½³åŒ–æ–¹å¼</h3>
<ul>
<li>
<p>$o=\text{softmax}(W_t(u,v,|u-v|))$</p>
<ul>
<li>å…¶ä¸­:
<ul>
<li>$u$ å’Œ $v$ åˆ†åˆ¥æ˜¯ä¸åŒå¥å­çš„å¥å‘é‡</li>
<li>$|u-v|$ æ˜¯å…©å€‹å¥å‘é‡çš„å·® (element-wise difference)</li>
<li>$W_t \in \mathbb{R}^{3n\times k}$
<ul>
<li>$n$ æ˜¯å¥å‘é‡çš„ç¶­åº¦</li>
<li>$k$ æ˜¯ label çš„æ•¸ç›®</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>å¦‚ä¸‹åœ– 1 æ‰€ç¤º
<img src="https://i.imgur.com/8MCr0S0.png" alt=""></p>
</li>
</ul>
<h3 id="è¿´æ­¸ä»»å‹™çš„æœ€ä½³åŒ–æ–¹å¼">è¿´æ­¸ä»»å‹™çš„æœ€ä½³åŒ–æ–¹å¼</h3>
<ul>
<li>å…ˆè¨ˆç®—ç›¸ä¼¼åº¦
<ul>
<li>$\textrm{cos_similarity}(s_u, s_v)$</li>
</ul>
</li>
<li>å† minimize mean-squared error</li>
<li>å¦‚ä¸‹åœ– 2 æ‰€ç¤º
<img src="https://i.imgur.com/7VCk0er.png" alt=""></li>
</ul>
<h3 id="triplet-ä»»å‹™çš„æœ€ä½³åŒ–æ–¹å¼">Triplet ä»»å‹™çš„æœ€ä½³åŒ–æ–¹å¼</h3>
<ul>
<li>é‡å° Wikipedia section triplets dataset (<a href="https://aclanthology.org/P18-2009.pdf">Dor et al., 2018</a>).</li>
<li>Minimize
<ul>
<li>$\textrm{max}(||s_a-s_p||-||s_a-s_n||+\epsilon, 0)$</li>
<li>$s_a$: an anchor sentence</li>
<li>$s_p$: a positive sentence</li>
<li>$s_n$: a negative sentence</li>
<li>$||\cdot||$: Euclidean distance</li>
<li>ç›®æ¨™æ˜¯è¦æœ€å°åŒ– $a$ å’Œ $p$ çš„è·é›¢ï¼Œä¸¦ä½¿ $a$ å’Œ $n$ çš„è·é›¢æœ€å¤§åŒ–</li>
<li>$\epsilon$: ç”¨ä¾†ç¢ºä¿æœ€ä½³åŒ–ä¹‹å¾Œ $a$ å’Œ $p$ çš„è·é›¢è‡³å°‘æœƒæ¯” $a$ å’Œ $n$ çš„è·é›¢å°‘ä¸€å€‹ $\epsilon$</li>
</ul>
</li>
</ul>
<h3 id="sbert-çš„è¨“ç·´">SBERT çš„è¨“ç·´</h3>
<ul>
<li>ä½¿ç”¨ SNLI å’Œ MNLI é€²è¡Œä¸‰åˆ†é¡ä»»å‹™çš„ fine-tuning
<ul>
<li>æ¬Šé‡åˆå§‹åŒ–
<ul>
<li>SBERT: ä½¿ç”¨ pre-trained BERT</li>
<li>RoBERTa: ä½¿ç”¨ pre-trained RoBERTa</li>
</ul>
</li>
</ul>
</li>
<li>è¨“ç·´æ™‚é–“: ==1 å€‹ epoch==</li>
<li>batch size 16</li>
<li>Adam optimizer</li>
<li>learning rate 2e-5</li>
<li>ä½¿ç”¨ 10% çš„ training data é€²è¡Œ linear learning rate warmup</li>
</ul>
<h2 id="å¯¦é©—çµæœ">å¯¦é©—çµæœ</h2>
<h3 id="sts-b">STS-B</h3>
<ul>
<li>æ ¹æ“š Table 2ï¼Œå¯ä»¥ç™¼ç¾åœ¨æ²’æœ‰ç¶“é fine-tuning çš„æƒ…æ³ä¸‹ï¼ŒSBERT-NLI æ¯” BERT embeddings è¡¨ç¾æ›´å¥½ï¼Œä¹Ÿå‹éå…ˆå‰çš„ sentence embeddings</li>
</ul>
</section>

  
  
  <footer class="mt-12 flex flex-wrap">
     
    <a
      class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]"
      href="https://mcps5601.github.io/tags/%E8%AB%96%E6%96%87"
      >è«–æ–‡</a
    >
     
    <a
      class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]"
      href="https://mcps5601.github.io/tags/nlp"
      >NLP</a
    >
     
    <a
      class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]"
      href="https://mcps5601.github.io/tags/bert"
      >BERT</a
    >
     
    <a
      class="mr-1.5 mb-1.5 rounded-lg bg-black/[3%] px-5 py-2 no-underline dark:bg-white/[8%]"
      href="https://mcps5601.github.io/tags/sentence_embeddings"
      >sentence_embeddings</a
    >
    
  </footer>
  

  
  
  
  <nav class="mt-24 flex rounded-lg bg-black/[3%] text-lg dark:bg-white/[8%]">
    
    <a
      class="flex w-1/2 items-center rounded-l-md p-6 pr-3 no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]"
      href="https://mcps5601.github.io/post/radbert-cl/"
      ><span class="mr-1.5">â†</span><span>RadBERT-CL: Factually-Aware Contrastive Learning For Radiology Report Classification</span></a
    >
    
    
    <a
      class="ml-auto flex w-1/2 items-center justify-end rounded-r-md p-6 pl-3 no-underline hover:bg-black/[2%] dark:hover:bg-white/[3%]"
      href="https://mcps5601.github.io/post/math-terms/"
      ><span>Math Terms</span><span class="ml-1.5">â†’</span></a
    >
    
  </nav>
  

  
  

  
  
</article>


    </main>

    <footer
  class="opaco mx-auto flex h-[5rem] max-w-3xl items-center px-8 text-[0.9em] opacity-60"
>
  <div class="mr-auto">
    &copy; 2025
    <a class="link" href="https://mcps5601.github.io">Ying-Jia Lin</a>
  </div>
  <a class="link mx-6" href="https://gohugo.io/" rel="noopener" target="_blank"
    >Powered by Hugoï¸ï¸</a
  >ï¸
  <a
    class="link"
    href="https://github.com/nanxiaobei/hugo-paper"
    rel="noopener"
    target="_blank"
    >Theme Paper</a
  >
  <div style="margin-bottom: 10px;">
    
  <a href="https://info.flagcounter.com/Bxzj"><img src="https://s05.flagcounter.com/count2/Bxzj/bg_FFFFFF/txt_000000/border_CCCCCC/columns_5/maxflags_15/viewers_0/labels_0/pageviews_1/flags_0/percent_0/" alt="Flag Counter" border="0"></a>
  </div>
</footer>
  </body>
</html>
